_target_: peft.LoraConfig
r: 8
lora_alpha: 8
# target_modules: ["c_attn", "c_proj", "c_fc", "c_proj", "lm_head"]
lora_dropout: 0.05
bias: "none"
task_type: "CAUSAL_LM"
inference_mode: false
